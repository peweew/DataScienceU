{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Submission Free-Response Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enron corporation was an American energy commodities and servies company, and was one of the world's major electricity, natural gas, communications and pulp and paper companies. At the end of 2001, it was revealed that its reported financial condition was sustained by institutionalized, systematic and creatively planned accouting fraud. \n",
    "\n",
    "With the development of machine learning technique, we are going to try a new method to assist the inspection institute and court to invest the case of the inner corruptions of Enron. We will use the features from the financial data and email data to label the person of interest, who has high chance to be related with the fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of our project is to predict the person of interest (poi) from the records of the features from the dataset. We will use a few machine learing technique to train our data and select the best fit algorithm and parameters to predict the potential poi person from the other features avaiable in dataset. \n",
    "\n",
    "In our datasets, we have total 146 records. We also have total 21 features, including 14 features related to finance records, 6 features related to email communication, and 1 feature named 'poi' for prediction. So there are total 20 features that could be used to train and predict for poi person. \n",
    "\n",
    "In our dataset, we have a few outliers. 'TOTAL' appears in the key of the dictionary of dataset and should be removed since it does not record a person's information. We also remove record with key 'LOCKHART EUGENE E' since all the features have NaN values except poi equal to false. This record will not provide us any useful information to predict the poi from the other features. The total number of records after removing outliner is 144. We also remove the feature named email_address since it is used to identify a person not related to poi feature. Since poi is also a feature but prediction, we only use the 19 featuers to predict the poi feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it.  \n",
    "### In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select the best features for our poi identifer, we use the SelectKBest function from sklearn module. We first rank all the 19 features as follow:\n",
    "\n",
    "| Feature | Score |\n",
    "| :--------| ------|\n",
    "|'exercised_stock_options' | 25.097|\n",
    "|'total_stock_value' | 24.468 | \n",
    "|'bonus' | 21.059 | \n",
    "|'salary' | 18.576| \n",
    "|'deferred_income' | 11.596|\n",
    "|'long_term_incentive' | 10.071|\n",
    "|'restricted_stock' | 9.346|\n",
    "|'total_payments'| 8.867|\n",
    "|'shared_receipt_with_poi' | 8.746|\n",
    "|'loan_advances'| 7.243|\n",
    "|'expenses'| 6.234|\n",
    "|'from_poi_to_this_person'| 5.344|\n",
    "|'other'| 4.205|\n",
    "|'from_this_person_to_poi'| 2.427|\n",
    "|'director_fees'| 2.108|\n",
    "|'to_messages'| 1.699|\n",
    "|'deferral_payments'| 0.217|\n",
    "|'from_messages'| 0.164|\n",
    "|'restricted_stock_deferred| 0.065|\n",
    "\n",
    "We select the first 9 features since these features has the highest scores. We are also interested in creating a feature by combining 'from_poi_to_this_person' and 'from_this_person_to_poi' together and get a new feature named 'poi_email_communication'. So the ten features that we selected are as follow:\n",
    "\n",
    " * exercised_stock_options\n",
    " * total_stock_value \n",
    " * bonus \n",
    " * salary \n",
    " * deferred_income \n",
    " * long_term_incentive\n",
    " * restricted_stock\n",
    " * total_payments \n",
    " * shared_receipt_with_poi \n",
    " * poi_email_communication \n",
    " \n",
    "For all the selected features, we use the MinMaxScaler to scale the values of each records in dataset. Since each features are measured on different unit, for instance the payment is in USD and email is in number, we need to scale all the values in range [0, 1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first divide our dataset into training set and testing set. We test seven machine learning algorithm, Naive Bayes, LogisticRegression, KMeans Cluster, SVC, DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifier, which are introduced in our course or mentioned in reading document. All the machine learning algorithm we use the default setting except the kmean cluster we use the cluster number equal to two since there are only non-poi and poi in our prediction range. In the begining we only use the accuracy_score measure to test the prediction accuracy of our dataset. But we found that all the machine learning algorithms have a good performance. This is because all our algorithm has high non-poi rate. So if the machine learning algorithm just predict all the poi as false, it can still get a high accuracy score. Therefore, in order to make a better test result, for each algorithm we calculate the accuracy score, precision score and recall score. We also run the evaluation function, which calculate the accuracy score, precision score and recall score, 1000 times, and for each time, we randomly select the seed of train_test_split algorithm to generate a random splitting train set and test set. We also compute the total score, which is the sum of the accuracy score, precision score and recall score, to evalute which algorithm has the best results on average. All the results for each machine learing algorithm as follow:\n",
    "\n",
    " | Algorithm | Accuracy_score  | Precision | Recall | Total Score|\n",
    " |:----- |:---- |:---- |:----  | :---- | \n",
    " | GaussianNB  |  0.857 |  0.428 | 0.453 | 1.725 |\n",
    " | LogisticRegression | 0.861 |  0.25 |  0.054 | 1.365 |\n",
    " | KMeans | 0.582 |  0.312 |  0.437 | 1.619 |\n",
    " | SVC | 0.88 |  0.0 | 0.0 | 0.861 |  \n",
    " | DecisionTreeClassifier | 0.8 |  0.332 | 0.386 | 1.174| \n",
    " | RandomForestClassifier | 0.841 | 0.594 | 0.2 | 1.347 |\n",
    " | AdaBoostClassifier |  0.825 |  0.198 |  0.181 |  1.328 |\n",
    " \n",
    " Based on the score in the table of each machine learning algorithm, we select the LogisticRegression as our candidate machine learing algorithm since it has the second highest best total score on the accuracy score, precision score and recall score. We could also select GuassianNB and KMeans as our candidate algorithm due to the high score achieved. Our reason to select LogisticRegression is we could optimize the parameter to get a better score than GaussianNB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well? How did you tune the parameters of your particular algorithm? What parameters did you tune?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the parameters of the three selected machine learning algorithms: GaussianNB and KMeans and LogisticRegression. For each algorithm we use GridSearchCV of sklearn model to selet the ooptimal parameters for each algorithm. For LogisticRegression we exhaustively search c and tol. For KMeans culsuter algorithm we search tol. Since Naive Bayes does not have parameters, so there is no optimazation on Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation of machine learning algorithm is to test if our machine learning algorithm has a good performance on new data. Therefore we need to use robust technique to train and evaluate our models on dataset. The more reliable of the validation we estimated on our model, the further we can push the performance and be confident on the operation of using our model.\n",
    "\n",
    "There are a few potential mistakes we can make in our machine learning models. For example, we may over fitting our features so there are a good performance on training dataset but poor performance on the testign dataset and practical usage. In our dataset, we use our own designed evaluation function in document, and also the tester.py provoided by project original file.\n",
    "\n",
    "Our own evaulation use the accuracy score, precision and recall for evaluating our model performance. We divide the dataset into training set and test set. We loop our evaluation algorithm 1000 times. For each time, we randomly set the training set and test set by choosing a new random seed. Finally we average the accuracy score, precision and recall scores on the 1000 times. The accuracy score equals to the ratio of the correct prediction, including poi and non-poi and all the predictions; the precision equals to the ratio of the correct predicted record as poi and the total record of predicting as poi; the recall equals to the ratio of the correct predicted record and the total record of true poi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Give at least 2 evaluation metrics and your average performance for each of them. Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result of evaluation on the three selected algorithm: Naive Bayes, KMeans and LogisticRegression as follow:\n",
    "\n",
    " | Algorithm | Accuracy_score  | Precision | Recall |\n",
    " |:----- |:---- |:---- |:----  | \n",
    " | GaussianNB  |  0.857 |  0.428 | 0.453 |\n",
    " | LogisticRegression | 0.721 |  0.389 |  0.668 | \n",
    " | KMeans | 0.747 |  0.409 |  0.507 | \n",
    " \n",
    "The result of test.py on the three select algorithm are as follow:\n",
    "\n",
    " | Algorithm | Accuracy_score  | Precision | Recall |\n",
    " |:----- |:---- |:---- |:----  | \n",
    " | GaussianNB  |  0.841 |  0.383 | 0.314 |\n",
    " | LogisticRegression | 0.399 |  0.121 |  0.562 | \n",
    " | KMeans | 0.850 |  0.287 |  0.080 | \n",
    " \n",
    " All the three algorithm perform quite well overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use machine learning algorithm to train and test the performance of 7 machine learning algorithms. We select three best performance algorithm as our final candidates. There are still some possible improvement in future. First the dataset has very limited size. There are total 146 records avaible. Since there are few data set, we can not get enough training set and test test for our algorithms. Second, there are very few poi person, that is 18, in our data set. If there would be more poi in our dataset, we could train our machine learning algorithm much better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
